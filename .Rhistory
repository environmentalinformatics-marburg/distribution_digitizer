library (reticulate)
reticulate::repl_python()
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
def download_file(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200:
filename = url.split('/')[-1]
output_path = os.path.join(output_dir, filename)
with open(output_path, 'wb') as file:
file.write(response.content)
print(f"Downloaded: {filename}")
else:
print(f"Failed to download file. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
def download_folder(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200:
soup = BeautifulSoup(response.content, 'html.parser')
for link in soup.find_all('a'):
href = link.get('href')
if href and not (href.startswith('?') or href.startswith('#')):
file_url = urljoin(url, href)
download_file(file_url, username, password, output_dir)
else:
print(f"Failed to access folder. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
password = "2qG9k4cj"
if __name__ == "__main__":
# Replace these with your actual credentials and URL
url = "http://85.214.102.111/data/books_examples/"
username = "digitizer"
password = password
output_dir = "C:/Users/user/Documents/dd/books/"
# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)
download_folder(url, username, password, output_dir)
if __name__ == "__main__":
# Replace these with your actual credentials and URL
url = "http://85.214.102.111/data/books_examples/"
username = "digitizer"
password = password
output_dir = "D:/distribution_digitizer/books/"
# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)
download_folder(url, username, password, output_dir)
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
def download_file(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200 and 'Content-Disposition' in response.headers:
filename = os.path.basename(urlparse(url).path)
output_path = os.path.join(output_dir, filename)
with open(output_path, 'wb') as file:
file.write(response.content)
print(f"Downloaded: {filename}")
else:
print(f"Failed to download file. URL: {url}, Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
def download_folder(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200:
soup = BeautifulSoup(response.content, 'html.parser')
for link in soup.find_all('a'):
href = link.get('href')
if href and not href.startswith(('?', '#')):  # Exclude sorting and navigation links
file_url = urljoin(url, href)
download_file(file_url, username, password, output_dir)
else:
print(f"Failed to access folder. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
if __name__ == "__main__":
# Replace these with your actual credentials and URL
url = "http://85.214.102.111/data/books_examples/"
username = "digitizer"
password = password
output_dir = "D:/distribution_digitizer/books/"
# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)
download_folder(url, username, password, output_dir)
password = "2qG9k4cj"
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
def download_file(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password), allow_redirects=True)
if response.status_code == 200 and 'Content-Disposition' in response.headers:
filename = os.path.basename(urlparse(url).path)
output_path = os.path.join(output_dir, filename)
with open(output_path, 'wb') as file:
file.write(response.content)
print(f"Downloaded: {filename}")
else:
print(f"Failed to download file. URL: {url}, Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
def download_folder(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200:
soup = BeautifulSoup(response.content, 'html.parser')
for link in soup.find_all('a'):
href = link.get('href')
if href and not href.startswith(('?', '#')):  # Exclude sorting and navigation links
file_url = urljoin(url, href)
# Handle URLs with trailing slash
if file_url.endswith('/'):
file_url = file_url.rstrip('/')  # Remove the trailing slash
download_file(file_url, username, password, output_dir)
else:
print(f"Failed to access folder. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
password = "2qG9k4cj"
if __name__ == "__main__":
# Replace these with your actual credentials and URL
url = "http://85.214.102.111/data/books_examples/"
username = "digitizer"
password = password
output_dir = "D:/distribution_digitizer/books/"
# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)
download_folder(url, username, password, output_dir)
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
def download_file(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password), allow_redirects=True)
if response.status_code == 200 and 'Content-Disposition' in response.headers:
filename = os.path.basename(urlparse(url).path)
output_path = os.path.join(output_dir, filename)
with open(output_path, 'wb') as file:
file.write(response.content)
print(f"Downloaded: {filename}")
else:
print(f"Failed to download file. URL: {url}, Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
def download_folder(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200:
soup = BeautifulSoup(response.content, 'html.parser')
for link in soup.find_all('a'):
href = link.get('href')
if href and not href.startswith(('?', '#')):  # Exclude sorting and navigation links
file_url = urljoin(url, href)
# Handle URLs with trailing slash
if file_url.endswith('/'):
file_url = file_url.rstrip('/')  # Remove the trailing slash
# Check if it's a subfolder and download files from the subfolder
if file_url.endswith(("png", "tif")):
download_file(file_url, username, password, output_dir)
else:
# If it's not a subfolder, traverse into the subfolder and download files
download_folder(file_url, username, password, output_dir)
else:
# Download individual files in the main directory
download_file(file_url, username, password, output_dir)
else:
print(f"Failed to access folder. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
if __name__ == "__main__":
# Replace these with your actual credentials and URL
url = "http://85.214.102.111/data/books_examples/"
username = "digitizer"
password = password
output_dir = "D:/distribution_digitizer/books/"
# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)
download_folder(url, username, password, output_dir)
def download_folder(url, username, password, output_dir):
try:
response = requests.get(url, auth=(username, password))
if response.status_code == 200:
soup = BeautifulSoup(response.content, 'html.parser')
for link in soup.find_all('a'):
href = link.get('href')
if href and not href.startswith(('?', '#')):  # Exclude sorting and navigation links
file_url = urljoin(url, href)
# Handle URLs with trailing slash
if file_url.endswith('/'):
file_url = file_url.rstrip('/')  # Remove the trailing slash
# Check if it's a subfolder and download files from the subfolder
if file_url.endswith(("png/", "tif/")):
download_file(file_url, username, password, output_dir)
else:
# If it's not a subfolder, traverse into the subfolder and download files
download_folder(file_url, username, password, output_dir)
else:
# Download individual files in the main directory
download_file(file_url, username, password, output_dir)
else:
print(f"Failed to access folder. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
print(f"An error occurred: {e}")
if __name__ == "__main__":
# Replace these with your actual credentials and URL
url = "http://85.214.102.111/data/books_examples/"
username = "digitizer"
password = password
output_dir = "D:/distribution_digitizer/books/"
# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)
download_folder(url, username, password, output_dir)
srplants = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRplants.csv")
colnames(srplants)
srplants = srplants[,-1]
colnames(srplants)
colnames(srplants) = c("PlotID", "Mean minimum temperature", "Mean maximum temperature",
"Average temperature", "Total Precipitation", "Mean elevation",
"Mean aspect", "Mean slope", "Mean NDVI", "Mean SAVI", "SD of NDVI",
"Mean of SAVI", "Plant SR", "Category")
predictors <- c("Mean minimum temperature", "Mean maximum temperature",
"Average temperature", "Total Precipitation", "Mean elevation",
"Mean aspect", "Mean slope", "Mean NDVI", "Mean SAVI")
library(caret)
featurePlot(x = srplants[, predictors],
y = srplants$Plant SR, type = c("p", "smooth"),
colnames(srplants) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "Plant_SR", "Category")
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(5,2))
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(5,2), col = "red")
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(5,2), col = "darkred")
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
png("D:/MSc_Phys_Geo/upscaling_project/depictions")
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png")
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png", res = 300)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 500, height = 500)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 500, height = 500, dpi = 1000)
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 500, height = 500, ppi = 1000)
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 500, height = 500, res = 1000)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 500, height = 500)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 1200, height = 1200)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 1200, height = 1200, res = 100)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 1200, height = 1200, res = 200)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 1200, height = 1200, res = 150)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
# read model data
srplants = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRpoll.csv")
# read model data
srplants = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRplants.csv")
# read model data
srpoll = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRpoll.csv")
# do some indexing and change column names
colnames(srpoll)
srpoll = srpoll[,-1]
colnames(srpoll) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "Pollinator_SR", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRpoll.png",
width = 1200, height = 1200, res = 150)
featurePlot(x = srpoll[, predictors],
y = srpoll$Pollinator_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
# read model data
spfi = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_index.csv")
# do some indexing and change column names
colnames(spfi)
spfi = spfi[,-1]
colnames(spfi) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "SPFI", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SPFI.png",
width = 1200, height = 1200, res = 150)
featurePlot(x = spfi[, predictors],
y = spfi$SPFI, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
srplants = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRplants.csv")
# do some indexing and change column names
colnames(srplants)
srplants = srplants[,-1]
colnames(srplants) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "Plant_SR", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 1200, height = 600, res = 150)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRplants.png",
width = 1200, height = 800, res = 150)
featurePlot(x = srplants[, predictors],
y = srplants$Plant_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
srpoll = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRpoll.csv")
# do some indexing and change column names
colnames(srpoll)
srpoll = srpoll[,-1]
colnames(srpoll) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "Pollinator_SR", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
# plot scatterplots and save as png file
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRpoll.png",
width = 1200, height = 1200, res = 150)
featurePlot(x = srpoll[, predictors],
y = srpoll$Pollinator_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
spfi = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_index.csv")
# do some indexing and change column names
colnames(spfi)
spfi = spfi[,-1]
colnames(spfi) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "SPFI", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
# plot scatterplots and save as png file
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SPFI.png",
width = 1200, height = 1200, res = 150)
featurePlot(x = spfi[, predictors],
y = spfi$SPFI, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
srpoll = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_SRpoll.csv")
# do some indexing and change column names
colnames(srpoll)
srpoll = srpoll[,-1]
colnames(srpoll) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "Pollinator_SR", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
# plot scatterplots and save as png file
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SRpoll.png",
width = 1200, height = 800, res = 150)
featurePlot(x = srpoll[, predictors],
y = srpoll$Pollinator_SR, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
spfi = read.csv("D:/MSc_Phys_Geo/upscaling_project/data/plot_level/combined/pred_index.csv")
# do some indexing and change column names
colnames(spfi)
spfi = spfi[,-1]
colnames(spfi) = c("PlotID", "Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI", "SD_of_NDVI",
"SD_of_SAVI", "SPFI", "Category")
# isolate colnames of predictor variables
predictors <- c("Mean_minimum_temperature", "Mean_maximum_temperature",
"Average_temperature", "Total_Precipitation", "Mean_elevation",
"Mean_aspect", "Mean_slope", "Mean_NDVI", "Mean_SAVI")
# plot scatterplots and save as png file
png("D:/MSc_Phys_Geo/upscaling_project/depictions/scatter_SPFI.png",
width = 1200, height = 800, res = 150)
featurePlot(x = spfi[, predictors],
y = spfi$SPFI, type = c("p", "smooth"),
plot = "scatter", layout = c(3,3), col = "darkred")
dev.off()
library(reticulate)
reticulate::repl_python()
input_start = "20230828:0800"
input_end = "20230828:1200"
START = dt.datetime.strptime(input_start, "%Y%m%d:%H%M")
from datetime import timedelta
import datetime as dt
from datetime import timedelta # Added on 2023-08-29 for time period splitting
START = dt.datetime.strptime(input_start, "%Y%m%d:%H%M")
END = dt.datetime.strptime(input_end, "%Y%m%d:%H%M")
time_period = timedelta(hours=1)
current_time = START
START_LIST = []
END_LIST = []
time_period = timedelta(hours=1)
current_time = START
while current_time < END:
next_time = current_time + time_period
# if-statement for exiting while condition, when the END timestamp is reached
if next_time > END:
next_time = END
START_LIST.append(current_time)
END_LIST.append(next_time)
current_time = next_time
while current_time < END:
next_time = current_time + time_period
# if-statement for exiting while condition, when the END timestamp is reached
if next_time > END:
next_time = END
START_LIST.append(current_time)
END_LIST.append(next_time)
current_time = next_time
START_LIST
END_LIST
library(reticulate) # Python binding for R.
setwd("D:/dd/2023-08-30/distribution_digitizer/") # uncomment this line for setting the working directory manually.
getwd() # print the path to the working directory for copying into the Digitizer application (Field: "Working Directory").
# start the main app
runApp('app.R') # the app itself
library(shiny) # shiny library necessary for starting the app
# start the main app
runApp('app.R') # the app itself
force(session)
force(input)
View(session)
View(output)
View(input)
# start the main app
runApp('app.R') # the app itself
input$pointCircleDetection
force(session)
View(output)
View(input)
View(session)
View(session)
View(session)
# start the main app
runApp('app.R') # the app itself
